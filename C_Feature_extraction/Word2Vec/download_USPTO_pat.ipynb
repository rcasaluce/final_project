{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "import zipfile\n",
    "import requests\n",
    "import pandas as pd\n",
    "import re\n",
    "import pathlib\n",
    "from os.path import expanduser as ospath\n",
    "\n",
    "def open_file(file):\n",
    "    \n",
    "    file_xml = open(file +'.xml', mode='r')\n",
    "    file_text_raw = file_xml.read()\n",
    "    file_xml.close()\n",
    "    text_file =re.compile(\"<\\?xml version=\\\"1\\.0\\\" encoding\\=\\\"UTF\\-8\\\"\\?>\")\n",
    "    file_text = text_file.split(file_text_raw)\n",
    "    \n",
    "    while '' in file_text:\n",
    "        file_text.remove('')\n",
    "    print(\"Number of patents :\", len(file_text))\n",
    "    \n",
    "    \n",
    "    publn_nr_list, title_list, type_list, num_claims_list, claim_list, abstract_list, classification_list, = ([] for i in range(7))\n",
    "\n",
    "    for text in file_text:\n",
    "    \n",
    "        publn_nr = re.findall('file\\=\\\"([U][S]\\w\\w\\d{6})\\-\\d{8}\\.XML\\\"', text)# publication number\n",
    "        type_pat =re.findall(\"<kind>([A-Z]\\d)</kind>\",text)# type of patent\n",
    "        titl =re.findall(\"<invention-title id=\\\"\\w{5,6}\\\">(.*?)</invention-title>\",text) #title of the invention\n",
    "        clas =  re.findall(r'<classification-cpc-text>(.*)</classification-cpc-text>',text)\n",
    "        cl = re.findall(\"<claim-text>[\\s\\S<]*</claim-text>\",text) \n",
    "        abstr = re.findall(\"\\<abstract id\\=\\\"abstract\\\"\\>\\n\\<p id\\=\\\"p\\-0001\\\" num\\=\\\"0000\\\"\\>(.*?)\\<\\/p\\>\\n\\<\\/abstract\\>\",text)\n",
    "        \n",
    "        #number of claims\n",
    "        num_claim_minus_1 = re.findall(r'<claim id=\"CLM-\\d*\" num=\"(\\d+)\">',str(cl))\n",
    "        if len(num_claim_minus_1) == 0:\n",
    "            num_claims = 1\n",
    "        else:\n",
    "            num_claims = len(num_claim_minus_1) + 1\n",
    "        \n",
    "        \n",
    "        #classiffication IPC\n",
    "        if len(clas) == 0:\n",
    "            classif = 'NA'\n",
    "        else:\n",
    "            classif = clas\n",
    "        \n",
    "        \n",
    "        #claims\n",
    "        if len(cl) == 0:\n",
    "            claims = 'NA'\n",
    "        else:\n",
    "            claims = cl\n",
    "\n",
    "        #Abstract\n",
    "        if len(abstr)==0:\n",
    "            abstract = 'NA'\n",
    "        else:    \n",
    "            abstract = abstr\n",
    "            \n",
    "        #Title\n",
    "        if len(titl)==0:\n",
    "            title = 'NA'\n",
    "        else:\n",
    "            title = titl\n",
    "        \n",
    "        if len(publn_nr)!=0:                             \n",
    "            publn_nr_list.extend(publn_nr)\n",
    "            type_list.append(type_pat)\n",
    "            num_claims_list.append(num_claims)\n",
    "            claim_list.append(claims)\n",
    "            abstract_list.extend(abstract)\n",
    "            classification_list.append(classif)\n",
    "            title_list.extend(title)\n",
    "\n",
    "    #cleaning claim text         \n",
    "    item=0\n",
    "    for items in claim_list:\n",
    "        claim_list[item]=re.sub('<.*?>','',str(claim_list[item]))\n",
    "        claim_list[item]=re.sub('\\n',',',str(claim_list[item]))\n",
    "        claim_list[item]=re.sub('\\,\\,\\,',',',str(claim_list[item]))\n",
    "        claim_list[item]=re.sub(\"[\\.][\\,][\\,]\",'.,',str(claim_list[item]))\n",
    "        claim_list[item]=re.sub(\"[\\,][\\,]\",',',str(claim_list[item]))\n",
    "        claim_list[item]=re.sub(\"[\\;][\\,]\",'; ',str(claim_list[item]))\n",
    "        item += 1\n",
    "        \n",
    "   #reference - adapted from - https://github.com/imoisharma/U.S.-Patents-Claims/blob/master/U.S.%20Patents.ipynb\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    return publn_nr_list, title_list, type_list, num_claims_list, claim_list, abstract_list, classification_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset(publn_nr_list, title_list, type_list, num_claims_list, claim_list, abstract_list, classification_list):\n",
    "    \n",
    "    data_frame = pd.DataFrame()\n",
    "    for i in range(len(publn_nr_list)):\n",
    "        add_row = {'publn_nr': publn_nr_list[i],\n",
    "                    'patent_title': title_list[i],\n",
    "                    'classification': classification_list[i][2:-1], \n",
    "                    'type': type_list[i],\n",
    "                    'number_of_claims':num_claims_list[i],\n",
    "                    'claims_text':claim_list[i][2:-2],\n",
    "                    'abstract':abstract_list[i]\n",
    "                        }\n",
    "        #append row to the dataframe\n",
    "        data_frame = data_frame.append(add_row, ignore_index=True)\n",
    "    \n",
    "    return data_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = '2005'#years go from 2001 to 2020\n",
    "\n",
    "URL = \"https://bulkdata.uspto.gov/data/patent/grant/redbook/fulltext/\"+ year + \"/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_file(URL):\n",
    "    \n",
    "    \"\"\"1. Download zip files, one at the time. \n",
    "        2. Uncrompresses the file and sent it to the parser\n",
    "        3. Deletes both compressed and uncompressed files\n",
    "        input = URL \n",
    "        output = CSV files save\"\"\"\n",
    "    \n",
    "    zip_file_not_correctly_downl = []\n",
    "    \n",
    "    for link in bs(requests.get(URL).text, 'html.parser').findAll(\"a\", attrs={'href': re.compile(\".zip\")}):\n",
    "        file_link = link.get('href')\n",
    "        print(file_link)\n",
    "        \n",
    "        \n",
    "        if file_link[2:-4]:\n",
    "        \n",
    "            with open(link.text, 'wb') as file:\n",
    "                response = requests.get(URL + file_link)\n",
    "                file.write(response.content)\n",
    "\n",
    "            try:\n",
    "                with zipfile.ZipFile(file_link, 'r') as file:\n",
    "                    print(file.printdir())\n",
    "\n",
    "                    print('Extracting files...')\n",
    "                    file.extractall()\n",
    "                    print('Complete!')\n",
    "\n",
    "                    file_n = file.filename[:-4]\n",
    "                    if file_n[-3] == '_':#some of the xml files have a different name, example 'ipg200317_r1.zip'\n",
    "                        file_n[ : -3]\n",
    "\n",
    "                    publn_nr_list, title_list, type_list, num_claims_list, claim_list, abstract_list, classification_list = open_file(file_n)\n",
    "            \n",
    "                    data_frame = dataset(publn_nr_list, title_list, type_list, num_claims_list, claim_list, abstract_list, classification_list)\n",
    "                \n",
    "                    data_frame.to_excel(ospath('~/code_final_project/C_Feature_extraction/Data_for_w2v/USPTO/db_'+ file_n + '.xlsx'), index = None, header = True)\n",
    "            \n",
    "            except zipfile.BadZipFile:\n",
    "                    \n",
    "                    print('Error: Zip file cannot be open')\n",
    "                    \n",
    "                    zip_file_not_correctly_downl.append(file_link[3:-4])\n",
    "                    \n",
    "                    continue\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "        file_to_rem = pathlib.Path(file_n + '.zip')\n",
    "        file_to_rem.unlink()\n",
    "            \n",
    "        file_to_rem = pathlib.Path(file_n + '.xml')\n",
    "        file_to_rem.unlink()\n",
    "        \n",
    "    \n",
    "            \n",
    "            \n",
    "get_file(URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
