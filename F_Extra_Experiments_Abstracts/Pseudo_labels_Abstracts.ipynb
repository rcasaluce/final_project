{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from numpy.random import seed\n",
    "seed(3)\n",
    "import numpy as np\n",
    "np.random.default_rng\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pandas as pd\n",
    "from pandas import read_csv\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "from os.path import expanduser as ospath\n",
    "import time\n",
    "import os\n",
    "os.chdir(\"C:/Users/rober/project/B_Data_pre_processing/My_functions\")\n",
    "from B_pre_processing_data import pre_process_db\n",
    "from A_merge_datasets import merge_select_columns\n",
    "os.chdir(\"C:/Users/rober/project/F_Extra_Experiments_Abstracts/\")\n",
    "\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion, make_pipeline\n",
    "from sklearn.model_selection import KFold,GridSearchCV, cross_val_score, train_test_split, RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Steps:\n",
    "\n",
    ">1. Load Pickley files\n",
    ">2. Load unlabelled dataset\n",
    ">3. Delete the patents from the unlabelled dataset that are solo in the labelled dataset\n",
    ">4. Labelling the unlabelled dataset using the predition model saved when trained the best model for the abstarcts\n",
    ">5. Train multple learning algorithms to choose one as the best\n",
    ">6. Train the best model - Random Forest\n",
    ">7. Train the best model - XGBoost\n",
    ">8. Evalute the best model with the labeleld test data - manually labelled data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Pickle files\n",
    "I load the **test features and test targets** that I used to learn the Binary classification model saved in **'project\\E_Models\\Abstracts'**. I need the test dataset to evaluate the new learning model which I train with data with pseudo labels with data manually labelled data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(ospath('~/code_final_project/E_Models/Abstracts/Pickle_files/X_test_abstracts.pickle'), 'rb') as data:\n",
    "    X_test = pickle.load(data)\n",
    "    \n",
    "with open(ospath('~/code_final_project/E_Models/Abstracts/Pickle_files/y_test_abstracts.pickle'), 'rb') as data:\n",
    "    y_test = pickle.load(data)\n",
    "    \n",
    "with open(ospath('~/code_final_project/E_Models/Abstracts/Pickle_files/X_train_abstracts.pickle'), 'rb') as data:\n",
    "    X_train = pickle.load(data)\n",
    "    \n",
    "with open(ospath('~/code_final_project/E_Models/Abstracts/Pickle_files/y_train_abstracts.pickle'), 'rb') as data:\n",
    "    y_train = pickle.load(data)\n",
    "    \n",
    "with open(ospath('~/code_final_project/B_Data_pre_processing/Pickle_files/Abstracts_cleaned.pickle'), 'rb') as data:\n",
    "    db = pickle.load(data)\n",
    "    \n",
    "with open(ospath('~/code_final_project/E_Models/Abstracts/Pickle_files/xgb_model_abstracts.pickle'), 'rb') as data:\n",
    "    xgb_fitted = pickle.load(data)\n",
    "    \n",
    "    \n",
    "with open(ospath('~/code_final_project/E_Models/Abstracts/Pickle_files/tfidf_tune_abstracts.pickle'), 'rb') as data:\n",
    "    tf_fitted = pickle.load(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load the unlabelled datasets\n",
    "Load all the datasets collected form USPTO and EPO offices which are unlabelled\n",
    "Data collected using the scripts in **'project\\A_Data_Collection'** and stored in **'project/Unlabelled_data'**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**USPTO** patents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#USPTO datasets unlabelled\n",
    "dt_LIB_us = pd.read_excel(ospath('~/code_final_project/Unlabelled_data/DB_LIB_USPTO.xlsx'),dtype=str)\n",
    "dt_LC_us = pd.read_excel(ospath('~/code_final_project/Unlabelled_data/DB_LC_USPTO.xlsx'),dtype=str)\n",
    "dt_SC_us = pd.read_excel(ospath('~/code_final_project/Unlabelled_data/DB_SC_USPTO.xlsx'),dtype=str)\n",
    "dt_FW_us = pd.read_excel(ospath('~/code_final_project/Unlabelled_data/DB_FW_USPTO.xlsx'),dtype=str)\n",
    "\n",
    "#drops rows with NAs\n",
    "dt_LIB_us = dt_LIB_us[dt_LIB_us['Publn_Nr'].notna()]\n",
    "dt_LC_us = dt_LC_us[dt_LC_us['Publn_Nr'].notna()]\n",
    "dt_SC_us = dt_SC_us[dt_SC_us['Publn_Nr'].notna()]\n",
    "dt_FW_us = dt_FW_us[dt_FW_us['Publn_Nr'].notna()]\n",
    "\n",
    "\n",
    "#keeps only three columns\n",
    "dt_FW_us = dt_FW_us[['Publn_Nr', 'Type', 'Text']]\n",
    "dt_LIB_us = dt_LIB_us[['Publn_Nr', 'Type', 'Text']]\n",
    "dt_LC_us = dt_LC_us[['Publn_Nr', 'Type', 'Text']]\n",
    "dt_SC_us = dt_SC_us[['Publn_Nr', 'Type', 'Text']]\n",
    "\n",
    "#change to lowercase name columns\n",
    "dt_FW_us.columns = ['publn_nr', 'type', 'text']\n",
    "dt_LIB_us.columns = ['publn_nr', 'type', 'text']\n",
    "dt_LC_us.columns = ['publn_nr', 'type', 'text']\n",
    "dt_SC_us.columns = ['publn_nr', 'type', 'text']\n",
    "\n",
    "#converts the column Publn_Nr is int type\n",
    "dt_LIB_us['publn_nr'] = np.int64(dt_LIB_us['publn_nr'])\n",
    "dt_LC_us['publn_nr'] = np.int64(dt_LC_us['publn_nr'])\n",
    "dt_FW_us['publn_nr'] = np.int64(dt_FW_us['publn_nr'])\n",
    "dt_SC_us['publn_nr'] = np.int64(dt_SC_us['publn_nr'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**EPO** patents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EPO datasets unlabelled\n",
    "dt_LIB_epo = pd.read_excel(ospath('~/code_final_project/Unlabelled_data/LIB_EPO.xlsx'),dtype=str)\n",
    "dt_LC_epo = pd.read_excel(ospath('~/code_final_project/Unlabelled_data/LC_EPO.xlsx'),dtype=str)\n",
    "dt_SC_epo = pd.read_excel(ospath('~/code_final_project/Unlabelled_data/SC_EPO.xlsx'),dtype=str)\n",
    "dt_FW_epo = pd.read_excel(ospath('~/code_final_project/Unlabelled_data/FW_EPO.xlsx'),dtype=str)\n",
    "\n",
    "#drops rows with NAs\n",
    "dt_LIB_epo = dt_LIB_epo[dt_LIB_epo['Text'].notna()]\n",
    "dt_LC_epo = dt_LC_epo[dt_LC_epo['Text'].notna()]\n",
    "dt_SC_epo = dt_SC_epo[dt_SC_epo['Text'].notna()]\n",
    "dt_FW_epo = dt_FW_epo[dt_FW_epo['Text'].notna()]\n",
    "\n",
    "#converts the column Publn_Nr is int type\n",
    "dt_LIB_epo['Publn_Nr'] = np.int64(dt_LIB_epo['Publn_Nr'])\n",
    "dt_LC_epo['Publn_Nr'] = np.int64(dt_LC_epo['Publn_Nr'])\n",
    "dt_FW_epo['Publn_Nr'] = np.int64(dt_FW_epo['Publn_Nr'])\n",
    "dt_SC_epo['Publn_Nr'] = np.int64(dt_SC_epo['Publn_Nr'])\n",
    "\n",
    "#keeps only three columns\n",
    "dt_FW_epo = dt_FW_epo[['Publn_Nr', 'Type', 'Text']]\n",
    "dt_LIB_epo = dt_LIB_epo[['Publn_Nr', 'Type', 'Text']]\n",
    "dt_LC_epo = dt_LC_epo[['Publn_Nr', 'Type', 'Text']]\n",
    "dt_SC_epo = dt_SC_epo[['Publn_Nr', 'Type', 'Text']]\n",
    "\n",
    "#change to lowercase name columns\n",
    "dt_FW_epo.columns = ['publn_nr', 'type', 'text']\n",
    "dt_LIB_epo.columns = ['publn_nr', 'type', 'text']\n",
    "dt_LC_epo.columns = ['publn_nr', 'type', 'text']\n",
    "dt_SC_epo.columns = ['publn_nr', 'type', 'text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge in one dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "unlab_data = merge_select_columns(dt_LIB_us, dt_SC_us, dt_FW_us, dt_LC_us, dt_LIB_epo, dt_LC_epo, dt_FW_epo, dt_SC_epo, labels = 'No')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>publn_nr</th>\n",
       "      <th>type</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10354828</td>\n",
       "      <td>Abstract</td>\n",
       "      <td>According to an embodiment of the present disc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>10085792</td>\n",
       "      <td>Abstract</td>\n",
       "      <td>An apparatus includes an instrument body and t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>9782215</td>\n",
       "      <td>Abstract</td>\n",
       "      <td>An ultrasonic surgical device comprises a hand...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>10343141</td>\n",
       "      <td>Abstract</td>\n",
       "      <td>MOFs are disclosed that can efficiently adsorb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>10337115</td>\n",
       "      <td>Abstract</td>\n",
       "      <td>Surface treated copper foils for use in high s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57635</th>\n",
       "      <td>3322002</td>\n",
       "      <td>Abstract</td>\n",
       "      <td>The present invention relates to an electroly...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57650</th>\n",
       "      <td>3327827</td>\n",
       "      <td>Abstract</td>\n",
       "      <td>The present invention provides a battery cell...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57682</th>\n",
       "      <td>3336962</td>\n",
       "      <td>Abstract</td>\n",
       "      <td>Methods of preparing hetero ionic complexes, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57707</th>\n",
       "      <td>3349273</td>\n",
       "      <td>Abstract</td>\n",
       "      <td>The present disclosure relates to an electrod...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57711</th>\n",
       "      <td>3360908</td>\n",
       "      <td>Abstract</td>\n",
       "      <td>Provided is a rubber composition for tires ac...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>108813 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       publn_nr      type                                               text\n",
       "0      10354828  Abstract  According to an embodiment of the present disc...\n",
       "11     10085792  Abstract  An apparatus includes an instrument body and t...\n",
       "31      9782215  Abstract  An ultrasonic surgical device comprises a hand...\n",
       "52     10343141  Abstract  MOFs are disclosed that can efficiently adsorb...\n",
       "60     10337115  Abstract  Surface treated copper foils for use in high s...\n",
       "...         ...       ...                                                ...\n",
       "57635   3322002  Abstract   The present invention relates to an electroly...\n",
       "57650   3327827  Abstract   The present invention provides a battery cell...\n",
       "57682   3336962  Abstract   Methods of preparing hetero ionic complexes, ...\n",
       "57707   3349273  Abstract   The present disclosure relates to an electrod...\n",
       "57711   3360908  Abstract   Provided is a rubber composition for tires ac...\n",
       "\n",
       "[108813 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unlab_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Delete the patents from the unlabelled dataset that are also in the labelled dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "194\n"
     ]
    }
   ],
   "source": [
    "#save in list the publication numbers of the patents used for the logistic above\n",
    "list_publ_num_uspto = db['publn_nr'].unique()\n",
    "\n",
    "#keeps only patents that are not used to train and test the best model for the Abstracts saved\n",
    "unlab_data = unlab_data[~unlab_data['publn_nr'].isin(list_publ_num_uspto)]\n",
    "print(len(list_publ_num_uspto))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pre-process the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "unlab_data = pre_process_db(unlab_data)#pre-process the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>publn_nr</th>\n",
       "      <th>type</th>\n",
       "      <th>text</th>\n",
       "      <th>text_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10354828</td>\n",
       "      <td>Abstract</td>\n",
       "      <td>According to an embodiment of the present disc...</td>\n",
       "      <td>accord embodiment present disclosure photocath...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>10085792</td>\n",
       "      <td>Abstract</td>\n",
       "      <td>An apparatus includes an instrument body and t...</td>\n",
       "      <td>apparatus include instrument body transmission...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>9782215</td>\n",
       "      <td>Abstract</td>\n",
       "      <td>An ultrasonic surgical device comprises a hand...</td>\n",
       "      <td>ultrasonic surgical device comprise handle ass...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>10343141</td>\n",
       "      <td>Abstract</td>\n",
       "      <td>MOFs are disclosed that can efficiently adsorb...</td>\n",
       "      <td>mofs disclose efficiently adsorb oxygen gas st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>10337115</td>\n",
       "      <td>Abstract</td>\n",
       "      <td>Surface treated copper foils for use in high s...</td>\n",
       "      <td>surface treat copper foil use high speed circu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    publn_nr      type                                               text  \\\n",
       "0   10354828  Abstract  According to an embodiment of the present disc...   \n",
       "11  10085792  Abstract  An apparatus includes an instrument body and t...   \n",
       "31   9782215  Abstract  An ultrasonic surgical device comprises a hand...   \n",
       "52  10343141  Abstract  MOFs are disclosed that can efficiently adsorb...   \n",
       "60  10337115  Abstract  Surface treated copper foils for use in high s...   \n",
       "\n",
       "                                           text_clean  \n",
       "0   accord embodiment present disclosure photocath...  \n",
       "11  apparatus include instrument body transmission...  \n",
       "31  ultrasonic surgical device comprise handle ass...  \n",
       "52  mofs disclose efficiently adsorb oxygen gas st...  \n",
       "60  surface treat copper foil use high speed circu...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unlab_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Labelling the unlabelled dataset using the predition model saved when trained the best model for the abstarcts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the best model saved from the binary classification model of the abstracts - **project\\E_Models\\Abstracts** - and with the TF-IDF vectorizer also for the same best model, I predict the labels for the unlabelled dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#word representation using the TF-IDF fitted for the best binary model of the abstracts\n",
    "X = unlab_data['text_clean']\n",
    "X_tf = tf_fitted.transform(X).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_lab = xgb_fitted.predict(X_tf)\n",
    "unlab_data['pred_labels'] = pred_lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>publn_nr</th>\n",
       "      <th>type</th>\n",
       "      <th>text</th>\n",
       "      <th>text_clean</th>\n",
       "      <th>pred_labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10354828</td>\n",
       "      <td>Abstract</td>\n",
       "      <td>According to an embodiment of the present disc...</td>\n",
       "      <td>accord embodiment present disclosure photocath...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>10085792</td>\n",
       "      <td>Abstract</td>\n",
       "      <td>An apparatus includes an instrument body and t...</td>\n",
       "      <td>apparatus include instrument body transmission...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>9782215</td>\n",
       "      <td>Abstract</td>\n",
       "      <td>An ultrasonic surgical device comprises a hand...</td>\n",
       "      <td>ultrasonic surgical device comprise handle ass...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>10343141</td>\n",
       "      <td>Abstract</td>\n",
       "      <td>MOFs are disclosed that can efficiently adsorb...</td>\n",
       "      <td>mofs disclose efficiently adsorb oxygen gas st...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>10337115</td>\n",
       "      <td>Abstract</td>\n",
       "      <td>Surface treated copper foils for use in high s...</td>\n",
       "      <td>surface treat copper foil use high speed circu...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57635</th>\n",
       "      <td>3322002</td>\n",
       "      <td>Abstract</td>\n",
       "      <td>The present invention relates to an electroly...</td>\n",
       "      <td>present invention relate electrolyte impregnat...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57650</th>\n",
       "      <td>3327827</td>\n",
       "      <td>Abstract</td>\n",
       "      <td>The present invention provides a battery cell...</td>\n",
       "      <td>present invention provide battery cell include...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57682</th>\n",
       "      <td>3336962</td>\n",
       "      <td>Abstract</td>\n",
       "      <td>Methods of preparing hetero ionic complexes, ...</td>\n",
       "      <td>methods prepare hetero ionic complexes ionic l...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57707</th>\n",
       "      <td>3349273</td>\n",
       "      <td>Abstract</td>\n",
       "      <td>The present disclosure relates to an electrod...</td>\n",
       "      <td>present disclosure relate electrode manufactur...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57711</th>\n",
       "      <td>3360908</td>\n",
       "      <td>Abstract</td>\n",
       "      <td>Provided is a rubber composition for tires ac...</td>\n",
       "      <td>provide rubber composition tire achieve balanc...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>108491 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       publn_nr      type                                               text  \\\n",
       "0      10354828  Abstract  According to an embodiment of the present disc...   \n",
       "11     10085792  Abstract  An apparatus includes an instrument body and t...   \n",
       "31      9782215  Abstract  An ultrasonic surgical device comprises a hand...   \n",
       "52     10343141  Abstract  MOFs are disclosed that can efficiently adsorb...   \n",
       "60     10337115  Abstract  Surface treated copper foils for use in high s...   \n",
       "...         ...       ...                                                ...   \n",
       "57635   3322002  Abstract   The present invention relates to an electroly...   \n",
       "57650   3327827  Abstract   The present invention provides a battery cell...   \n",
       "57682   3336962  Abstract   Methods of preparing hetero ionic complexes, ...   \n",
       "57707   3349273  Abstract   The present disclosure relates to an electrod...   \n",
       "57711   3360908  Abstract   Provided is a rubber composition for tires ac...   \n",
       "\n",
       "                                              text_clean  pred_labels  \n",
       "0      accord embodiment present disclosure photocath...            1  \n",
       "11     apparatus include instrument body transmission...            1  \n",
       "31     ultrasonic surgical device comprise handle ass...            1  \n",
       "52     mofs disclose efficiently adsorb oxygen gas st...            1  \n",
       "60     surface treat copper foil use high speed circu...            1  \n",
       "...                                                  ...          ...  \n",
       "57635  present invention relate electrolyte impregnat...            1  \n",
       "57650  present invention provide battery cell include...            1  \n",
       "57682  methods prepare hetero ionic complexes ionic l...            0  \n",
       "57707  present disclosure relate electrode manufactur...            1  \n",
       "57711  provide rubber composition tire achieve balanc...            1  \n",
       "\n",
       "[108491 rows x 5 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unlab_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>publn_nr</th>\n",
       "      <th>type</th>\n",
       "      <th>text</th>\n",
       "      <th>text_clean</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pred_labels</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3069</td>\n",
       "      <td>3069</td>\n",
       "      <td>3069</td>\n",
       "      <td>3069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>105422</td>\n",
       "      <td>105422</td>\n",
       "      <td>105422</td>\n",
       "      <td>105422</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             publn_nr    type    text  text_clean\n",
       "pred_labels                                      \n",
       "0                3069    3069    3069        3069\n",
       "1              105422  105422  105422      105422"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unlab_data.groupby(by='pred_labels').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extremely unbalenced"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. train multple learning algorithms to choose one as the best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I run three algorithm, a Logistic Regression, XGBoost and Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_pseudo = unlab_data['text_clean']\n",
    "y_train_pseudo = unlab_data['pred_labels']\n",
    "X_train_pseudod_tf = tf_fitted.transform(X_train_pseudo).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_tf = tf_fitted.transform(X_test).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "oversample = SMOTE()\n",
    "X_train_pseudo_bal, y_train_pseudo_bal = oversample.fit_resample(X_train_pseudod_tf, y_train_pseudo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the test data: \n",
      "0.9102564102564102\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.14      0.22         7\n",
      "           1       0.92      0.99      0.95        71\n",
      "\n",
      "    accuracy                           0.91        78\n",
      "   macro avg       0.71      0.56      0.59        78\n",
      "weighted avg       0.88      0.91      0.89        78\n",
      "\n",
      "Confusion Matrix : \n",
      "[[ 1  6]\n",
      " [ 1 70]]\n"
     ]
    }
   ],
   "source": [
    "seed(3)\n",
    "xbg = xgb.XGBClassifier(objective = 'binary:logistic', n_jobs=-1)\n",
    "xbg.fit(X_train_pseudo_bal, y_train_pseudo_bal )\n",
    "xbg_pred = xbg.predict(X_test_tf)\n",
    "\n",
    "print(\"Accuracy on the test data: \")\n",
    "print(metrics.accuracy_score(y_test, xbg_pred))\n",
    "print(\"Classification report\")\n",
    "print(metrics.classification_report(y_test, xbg_pred))\n",
    "print('Confusion Matrix : ')\n",
    "print(metrics.confusion_matrix(y_test, xbg_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the test data: \n",
      "0.8333333333333334\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         7\n",
      "           1       0.90      0.92      0.91        71\n",
      "\n",
      "    accuracy                           0.83        78\n",
      "   macro avg       0.45      0.46      0.45        78\n",
      "weighted avg       0.82      0.83      0.83        78\n",
      "\n",
      "Confusion Matrix : \n",
      "[[ 0  7]\n",
      " [ 6 65]]\n"
     ]
    }
   ],
   "source": [
    "logi = LogisticRegression( random_state=0, n_jobs=-1)\n",
    "logi.fit(X_train_pseudo_bal, y_train_pseudo_bal)\n",
    "logi_pred = logi.predict(X_test_tf)\n",
    "\n",
    "\n",
    "print(\"Accuracy on the test data: \")\n",
    "print(metrics.accuracy_score(y_test, logi_pred))\n",
    "print(\"Classification report\")\n",
    "print(metrics.classification_report(y_test, logi_pred))\n",
    "print('Confusion Matrix : ')\n",
    "print(metrics.confusion_matrix(y_test, logi_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on validation data: \n",
      " 0.9230769230769231\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.14      0.25         7\n",
      "           1       0.92      1.00      0.96        71\n",
      "\n",
      "    accuracy                           0.92        78\n",
      "   macro avg       0.96      0.57      0.60        78\n",
      "weighted avg       0.93      0.92      0.90        78\n",
      "\n",
      "Confusion Matrix validation: \n",
      "[[ 1  6]\n",
      " [ 0 71]]\n"
     ]
    }
   ],
   "source": [
    "random.seed(2)\n",
    "rf = RandomForestClassifier(random_state = 8, n_jobs = -1)\n",
    "rf.fit(X_train_pseudo_bal, y_train_pseudo_bal)\n",
    "rf_pred = rf.predict(X_test_tf)\n",
    "\n",
    "print(\"Accuracy on validation data: \\n\",metrics.accuracy_score(y_test, rf_pred))\n",
    "print(\"Classification report: \\n\",metrics.classification_report(y_test, rf_pred))\n",
    "print('Confusion Matrix validation: \\n' + str(metrics.confusion_matrix(y_test, rf_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Train the best model - Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will run and tune the random forest algorithm since it is the best one here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I split first the unlabelled dataset with the predicted labels in three sets. \n",
    "### Train 50%, validation 25% and test 25%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_ps, X_val_ps, y_train_ps , y_val_ps = train_test_split(unlab_data['text_clean'], \n",
    "                                                    unlab_data['pred_labels'], test_size=0.5, random_state=8, stratify = unlab_data['pred_labels'])\n",
    "\n",
    "X_val_ps, X_test_ps, y_val_ps , y_test_ps = train_test_split(X_val_ps, \n",
    "                                                    y_val_ps, test_size=0.5, random_state=8, stratify = y_val_ps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tune Hyperparameters TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 20 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  28 tasks      | elapsed:   52.5s\n",
      "[Parallel(n_jobs=2)]: Done  40 out of  40 | elapsed:  1.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best set of parameters: \n",
      " [('tfidf', TfidfVectorizer(lowercase=False, max_features=300, norm='l1')), ('clf', OneVsRestClassifier(estimator=RandomForestClassifier(random_state=8)))]\n"
     ]
    }
   ],
   "source": [
    "random.seed(2)\n",
    "pipe_grid = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(lowercase=False), ),\n",
    "    ('clf', OneVsRestClassifier(RandomForestClassifier(random_state = 8))),\n",
    "])\n",
    "param_grid = {\n",
    "    'tfidf__norm' :('l1', 'l2'),\n",
    "    'tfidf__max_features' : (300, 350, 400, 450,500),\n",
    "    'tfidf__sublinear_tf' : [True, False]\n",
    "}\n",
    "\n",
    "grid_search_tfidf = GridSearchCV(pipe_grid, param_grid, cv=2, n_jobs=2, verbose=3)\n",
    "grid_search_tfidf.fit(X_val_ps, y_val_ps)\n",
    "\n",
    "\n",
    "print(\"Best set of parameters: \\n\" ,grid_search_tfidf.best_estimator_.steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_tune = grid_search_tfidf.best_estimator_[0]\n",
    "\n",
    "X_train_ps_tf_tune = tfidf_tune.fit_transform(X_train_ps).toarray()\n",
    "X_test_ps_tf_tune = tfidf_tune.transform(X_test_ps).toarray()\n",
    "X_val_ps_tf_tune = tfidf_tune.transform(X_val_ps).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### By using SMOTE, I balanced the unlabelled dataset since it also very unbalanced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "balance = SMOTE()\n",
    "X_train_ps_tf_tune_bal, y_train_ps_tf_tune_bal = balance.fit_resample(X_train_ps_tf_tune, y_train_ps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and evaluate Random Forest algorithm with TF-IDF tuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on validation data: \n",
      " 0.9929211370423626\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.78      0.86       768\n",
      "           1       0.99      1.00      1.00     26355\n",
      "\n",
      "    accuracy                           0.99     27123\n",
      "   macro avg       0.98      0.89      0.93     27123\n",
      "weighted avg       0.99      0.99      0.99     27123\n",
      "\n",
      "Confusion Matrix validation: \n",
      "[[  598   170]\n",
      " [   22 26333]]\n"
     ]
    }
   ],
   "source": [
    "random.seed(2)\n",
    "rf_tf_tune = RandomForestClassifier(random_state = 8, n_jobs = -1)\n",
    "rf_tf_tune.fit(X_train_ps_tf_tune_bal, y_train_ps_tf_tune_bal)\n",
    "rf_tf_tune_pred = rf_tf_tune.predict(X_val_ps_tf_tune)\n",
    "\n",
    "print(\"Accuracy on validation data: \\n\",metrics.accuracy_score(y_val_ps, rf_tf_tune_pred))\n",
    "print(\"Classification report: \\n\",metrics.classification_report(y_val_ps, rf_tf_tune_pred))\n",
    "print('Confusion Matrix validation: \\n' + str(metrics.confusion_matrix(y_val_ps, rf_tf_tune_pred)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the test data: \n",
      " 0.9928842679644582\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.77      0.86       767\n",
      "           1       0.99      1.00      1.00     26356\n",
      "\n",
      "    accuracy                           0.99     27123\n",
      "   macro avg       0.98      0.88      0.93     27123\n",
      "weighted avg       0.99      0.99      0.99     27123\n",
      "\n",
      "Confusion Matrix test: \n",
      "[[  588   179]\n",
      " [   14 26342]]\n"
     ]
    }
   ],
   "source": [
    "random.seed(2)\n",
    "rf_tf_tune_pred_test = rf_tf_tune.predict(X_test_ps_tf_tune)\n",
    "print(\"Accuracy on the test data: \\n\", metrics.accuracy_score(y_test_ps, rf_tf_tune_pred_test))\n",
    "print(\"Classification report: \\n\",metrics.classification_report(y_test_ps, rf_tf_tune_pred_test))\n",
    "print('Confusion Matrix test: \\n' + str(metrics.confusion_matrix(y_test_ps, rf_tf_tune_pred_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tune hyperparameters Random Forest algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'min_samples_leaf': [1, 2, 4],\n",
    "              'min_samples_split' : [2, 5, 10],\n",
    "             'max_features' : ['auto', 'sqrt'],\n",
    "              'max_depth': [20, 40, 60, 80, 100, None],\n",
    "              'n_estimators' : [200, 400, 600, 800, 1000],\n",
    "             'bootstrap' : [True, False]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 150 out of 150 | elapsed: 82.0min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, estimator=RandomForestClassifier(random_state=8),\n",
       "                   n_iter=50,\n",
       "                   param_distributions={'bootstrap': [True, False],\n",
       "                                        'max_depth': [20, 40, 60, 80, 100,\n",
       "                                                      None],\n",
       "                                        'max_features': ['auto', 'sqrt'],\n",
       "                                        'min_samples_leaf': [1, 2, 4],\n",
       "                                        'min_samples_split': [2, 5, 10],\n",
       "                                        'n_estimators': [200, 400, 600, 800,\n",
       "                                                         1000]},\n",
       "                   scoring='accuracy', verbose=1)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.seed(2)\n",
    "rand_for = RandomForestClassifier(random_state=8)\n",
    "\n",
    "random_search_rf = RandomizedSearchCV(estimator=rand_for,\n",
    "                                   param_distributions=param_grid,\n",
    "                                   n_iter=50,\n",
    "                                   scoring='accuracy',\n",
    "                                   cv=3, \n",
    "                                   verbose=1)\n",
    "\n",
    "# Fit the random search model\n",
    "random_search_rf.fit(X_val_ps_tf_tune, y_val_ps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and evaluate Random forest with both TF-IDF and algorithm tuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on validation data: \n",
      " 0.9929211370423626\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.77      0.86       768\n",
      "           1       0.99      1.00      1.00     26355\n",
      "\n",
      "    accuracy                           0.99     27123\n",
      "   macro avg       0.98      0.88      0.93     27123\n",
      "weighted avg       0.99      0.99      0.99     27123\n",
      "\n",
      "Confusion Matrix validation: \n",
      "[[  591   177]\n",
      " [   15 26340]]\n"
     ]
    }
   ],
   "source": [
    "random.seed(2)\n",
    "rf_both_tune = random_search_rf.best_estimator_\n",
    "rf_both_tune.fit(X_train_ps_tf_tune_bal, y_train_ps_tf_tune_bal)\n",
    "rf_both_tune_pred = rf_both_tune.predict(X_val_ps_tf_tune)\n",
    "\n",
    "print(\"Accuracy on validation data: \\n\",metrics.accuracy_score(y_val_ps, rf_both_tune_pred))\n",
    "print(\"Classification report: \\n\",metrics.classification_report(y_val_ps, rf_both_tune_pred))\n",
    "print('Confusion Matrix validation: \\n' + str(metrics.confusion_matrix(y_val_ps, rf_both_tune_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the test data: \n",
      " 0.9923681008737971\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.75      0.85       767\n",
      "           1       0.99      1.00      1.00     26356\n",
      "\n",
      "    accuracy                           0.99     27123\n",
      "   macro avg       0.99      0.87      0.92     27123\n",
      "weighted avg       0.99      0.99      0.99     27123\n",
      "\n",
      "Confusion Matrix test: \n",
      "[[  573   194]\n",
      " [   13 26343]]\n"
     ]
    }
   ],
   "source": [
    "random.seed(2)\n",
    "rf_both_tune_pred_test = rf_both_tune.predict(X_test_ps_tf_tune)\n",
    "print(\"Accuracy on the test data: \\n\", metrics.accuracy_score(y_test_ps, rf_both_tune_pred_test))\n",
    "print(\"Classification report: \\n\",metrics.classification_report(y_test_ps, rf_both_tune_pred_test))\n",
    "print('Confusion Matrix test: \\n' + str(metrics.confusion_matrix(y_test_ps, rf_both_tune_pred_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the model using the test data set split from the labelled dataset\n",
    "Random Forest with only TF-IDF tuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_tf_tune = tfidf_tune.transform(X_test).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the test data: \n",
      " 0.9230769230769231\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.14      0.25         7\n",
      "           1       0.92      1.00      0.96        71\n",
      "\n",
      "    accuracy                           0.92        78\n",
      "   macro avg       0.96      0.57      0.60        78\n",
      "weighted avg       0.93      0.92      0.90        78\n",
      "\n",
      "Confusion Matrix test: \n",
      "[[ 1  6]\n",
      " [ 0 71]]\n"
     ]
    }
   ],
   "source": [
    "random.seed(2)\n",
    "rf_tf_tune_pred_test_labelled = rf_tf_tune.predict(X_test_tf_tune)\n",
    "print(\"Accuracy on the test data: \\n\", metrics.accuracy_score(y_test, rf_tf_tune_pred_test_labelled))\n",
    "print(\"Classification report: \\n\",metrics.classification_report(y_test, rf_tf_tune_pred_test_labelled))\n",
    "print('Confusion Matrix test: \\n' + str(metrics.confusion_matrix(y_test, rf_tf_tune_pred_test_labelled)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Train the best model - XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tune Hyperparameters for TF-IDF for XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 20 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:   52.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for the TF-IDF: [('tfidf', TfidfVectorizer(lowercase=False, max_features=400, norm='l1', sublinear_tf=True)), ('clf', OneVsRestClassifier(estimator=XGBClassifier(base_score=None, booster=None,\n",
      "                                            colsample_bylevel=None,\n",
      "                                            colsample_bynode=None,\n",
      "                                            colsample_bytree=None, gamma=None,\n",
      "                                            gpu_id=None, importance_type='gain',\n",
      "                                            interaction_constraints=None,\n",
      "                                            learning_rate=None,\n",
      "                                            max_delta_step=None, max_depth=None,\n",
      "                                            min_child_weight=None, missing=nan,\n",
      "                                            monotone_constraints=None,\n",
      "                                            n_estimators=100, n_jobs=-1,\n",
      "                                            num_parallel_tree=None,\n",
      "                                            random_state=None, reg_alpha=None,\n",
      "                                            reg_lambda=None,\n",
      "                                            scale_pos_weight=None,\n",
      "                                            subsample=None, tree_method=None,\n",
      "                                            validate_parameters=None,\n",
      "                                            verbosity=None)))]\n"
     ]
    }
   ],
   "source": [
    "random.seed(2)\n",
    "pipeline_grid = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(lowercase=False)),\n",
    "    ('clf', OneVsRestClassifier(xgb.XGBClassifier(objective = 'binary:logistic', n_jobs=-1))),\n",
    "])\n",
    "param_grid = {\n",
    "    'tfidf__norm' :('l1', 'l2'),\n",
    "    'tfidf__max_features' : (300, 350, 400, 450,500),\n",
    "    'tfidf__sublinear_tf' : [True, False]\n",
    "\n",
    "}\n",
    "\n",
    "grid_search_tfidf_xgb = GridSearchCV(pipeline_grid, param_grid, cv=2, verbose=1, n_jobs=-1)\n",
    "grid_search_tfidf_xgb.fit(X_val_ps, y_val_ps)\n",
    "\n",
    "print(\"Best parameters for the TF-IDF: {}\".format(grid_search_tfidf_xgb.best_estimator_.steps))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit with the new vectorizer tune and balance the data with SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_xb = grid_search_tfidf_xgb.best_estimator_[0]\n",
    "\n",
    "X_train_ps_tf_tune_xb = tfidf_xb.fit_transform(X_train_ps).toarray()\n",
    "X_test_ps_tf_tune_xb = tfidf_xb.transform(X_test_ps).toarray()\n",
    "X_val_ps_tf_tune_xb = tfidf_xb.transform(X_val_ps).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "balance = SMOTE()\n",
    "X_train_ps_tf_tune_bal_xb, y_train_ps_tf_tune_bal_xb = balance.fit_resample(X_train_ps_tf_tune_xb, y_train_ps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and evaluate the model XGBoost with TF-IDF tuned "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on validation data: \n",
      " 0.9966080448327987\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94       768\n",
      "           1       1.00      1.00      1.00     26355\n",
      "\n",
      "    accuracy                           1.00     27123\n",
      "   macro avg       0.97      0.97      0.97     27123\n",
      "weighted avg       1.00      1.00      1.00     27123\n",
      "\n",
      "Confusion Matrix validation: \n",
      "[[  724    44]\n",
      " [   48 26307]]\n"
     ]
    }
   ],
   "source": [
    "random.seed(2)\n",
    "xb_tf_tune = xgb.XGBClassifier(objective = 'binary:logistic', n_jobs=-1)\n",
    "xb_tf_tune.fit(X_train_ps_tf_tune_bal_xb, y_train_ps_tf_tune_bal_xb)\n",
    "xb_tf_tune_pred = xb_tf_tune.predict(X_val_ps_tf_tune_xb)\n",
    "\n",
    "\n",
    "print(\"Accuracy on validation data: \\n\",metrics.accuracy_score(y_val_ps, xb_tf_tune_pred))\n",
    "print(\"Classification report: \\n\",metrics.classification_report(y_val_ps, xb_tf_tune_pred))\n",
    "print('Confusion Matrix validation: \\n' + str(metrics.confusion_matrix(y_val_ps, xb_tf_tune_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test data: \n",
      " 0.9963868303653726\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.93      0.94       767\n",
      "           1       1.00      1.00      1.00     26356\n",
      "\n",
      "    accuracy                           1.00     27123\n",
      "   macro avg       0.97      0.97      0.97     27123\n",
      "weighted avg       1.00      1.00      1.00     27123\n",
      "\n",
      "Confusion Matrix test: \n",
      "[[  715    52]\n",
      " [   46 26310]]\n"
     ]
    }
   ],
   "source": [
    "random.seed(2)\n",
    "xb_tf_tune_pred_test = xb_tf_tune.predict(X_test_ps_tf_tune_xb)\n",
    "print(\"Accuracy on test data: \\n\",metrics.accuracy_score(y_test_ps, xb_tf_tune_pred_test))\n",
    "print(\"Classification report: \\n\",metrics.classification_report(y_test_ps, xb_tf_tune_pred_test))\n",
    "print('Confusion Matrix test: \\n' + str(metrics.confusion_matrix(y_test_ps, xb_tf_tune_pred_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tune Hyperparameters XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'max_depth': [2,4,6,8,10],\n",
    "    'n_estimators': [60, 10,120,160,200, 240],\n",
    "    'learning_rate': [0.1, 0.01, 0.05, 0.009]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 150 out of 150 | elapsed: 23.2min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3,\n",
       "                   estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                           colsample_bylevel=None,\n",
       "                                           colsample_bynode=None,\n",
       "                                           colsample_bytree=None, gamma=None,\n",
       "                                           gpu_id=None, importance_type='gain',\n",
       "                                           interaction_constraints=None,\n",
       "                                           learning_rate=None,\n",
       "                                           max_delta_step=None, max_depth=None,\n",
       "                                           min_child_weight=None, missing=nan,\n",
       "                                           monotone_constraints=None,\n",
       "                                           n_estimators=100, n_jobs=-1,\n",
       "                                           num_parallel_tree=None,\n",
       "                                           random_state=None, reg_alpha=None,\n",
       "                                           reg_lambda=None,\n",
       "                                           scale_pos_weight=None,\n",
       "                                           subsample=None, tree_method=None,\n",
       "                                           validate_parameters=None,\n",
       "                                           verbosity=None),\n",
       "                   n_iter=50,\n",
       "                   param_distributions={'learning_rate': [0.1, 0.01, 0.05,\n",
       "                                                          0.009],\n",
       "                                        'max_depth': [2, 4, 6, 8, 10],\n",
       "                                        'n_estimators': [60, 10, 120, 160, 200,\n",
       "                                                         240]},\n",
       "                   scoring='accuracy', verbose=1)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.seed(2)\n",
    "xb = xgb.XGBClassifier(objective = 'binary:logistic', n_jobs=-1)\n",
    "\n",
    "\n",
    "\n",
    "# Definition of the random search\n",
    "random_search_xb = RandomizedSearchCV(estimator=xb,\n",
    "                                   param_distributions=param_grid,\n",
    "                                   n_iter=50,\n",
    "                                   scoring='accuracy',\n",
    "                                   cv=3, \n",
    "                                   verbose=1)\n",
    "\n",
    "# Fit the random search model\n",
    "random_search_xb.fit(X_val_ps_tf_tune_xb, y_val_ps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on validation data: \n",
      " 0.9964974375990856\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94       768\n",
      "           1       1.00      1.00      1.00     26355\n",
      "\n",
      "    accuracy                           1.00     27123\n",
      "   macro avg       0.97      0.97      0.97     27123\n",
      "weighted avg       1.00      1.00      1.00     27123\n",
      "\n",
      "Confusion Matrix validation: \n",
      "[[  720    48]\n",
      " [   47 26308]]\n"
     ]
    }
   ],
   "source": [
    "random.seed(2)\n",
    "xb_both_tune = random_search_xb.best_estimator_\n",
    "xb_both_tune.fit(X_train_ps_tf_tune_bal_xb, y_train_ps_tf_tune_bal_xb)\n",
    "xb_both_tune_pred = xb_both_tune.predict(X_val_ps_tf_tune_xb)\n",
    "\n",
    "\n",
    "print(\"Accuracy on validation data: \\n\",metrics.accuracy_score(y_val_ps, xb_both_tune_pred))\n",
    "print(\"Classification report: \\n\",metrics.classification_report(y_val_ps, xb_both_tune_pred))\n",
    "print('Confusion Matrix validation: \\n' + str(metrics.confusion_matrix(y_val_ps, xb_both_tune_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test data: \n",
      " 0.9965711757548944\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.93      0.94       767\n",
      "           1       1.00      1.00      1.00     26356\n",
      "\n",
      "    accuracy                           1.00     27123\n",
      "   macro avg       0.97      0.96      0.97     27123\n",
      "weighted avg       1.00      1.00      1.00     27123\n",
      "\n",
      "Confusion Matrix test: \n",
      "[[  711    56]\n",
      " [   37 26319]]\n"
     ]
    }
   ],
   "source": [
    "random.seed(2)\n",
    "xb_both_tune_pred_test = xb_both_tune.predict(X_test_ps_tf_tune_xb)\n",
    "print(\"Accuracy on test data: \\n\",metrics.accuracy_score(y_test_ps, xb_both_tune_pred_test))\n",
    "print(\"Classification report: \\n\",metrics.classification_report(y_test_ps, xb_both_tune_pred_test))\n",
    "print('Confusion Matrix test: \\n' + str(metrics.confusion_matrix(y_test_ps, xb_both_tune_pred_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the model using the test data set split from the labelled dataset\n",
    "XGBoost with TF-IDF and algorithm tuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_tf_tune = tfidf_xb.transform(X_test).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test data: \n",
      " 0.9102564102564102\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.14      0.22         7\n",
      "           1       0.92      0.99      0.95        71\n",
      "\n",
      "    accuracy                           0.91        78\n",
      "   macro avg       0.71      0.56      0.59        78\n",
      "weighted avg       0.88      0.91      0.89        78\n",
      "\n",
      "Confusion Matrix test: \n",
      "[[ 1  6]\n",
      " [ 1 70]]\n"
     ]
    }
   ],
   "source": [
    "random.seed(2)\n",
    "xb_both_tune_pred_test_original = xb_both_tune.predict(X_test_tf_tune)\n",
    "print(\"Accuracy on test data: \\n\",metrics.accuracy_score(y_test, xb_both_tune_pred_test_original))\n",
    "print(\"Classification report: \\n\",metrics.classification_report(y_test, xb_both_tune_pred_test_original))\n",
    "print('Confusion Matrix test: \\n' + str(metrics.confusion_matrix(y_test, xb_both_tune_pred_test_original)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Both the best model using pseudo labelling data did not improve the original model with just an abstract classified correctly out 7."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
